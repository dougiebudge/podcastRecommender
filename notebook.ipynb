{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 35: expected 26 fields, saw 28\\nSkipping line 42: expected 26 fields, saw 28\\nSkipping line 45: expected 26 fields, saw 42\\nSkipping line 59: expected 26 fields, saw 42\\nSkipping line 2235: expected 26 fields, saw 40\\nSkipping line 3131: expected 26 fields, saw 28\\nSkipping line 3161: expected 26 fields, saw 28\\nSkipping line 3166: expected 26 fields, saw 30\\n'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"desert-island-discs-episodes.csv\", sep=\"\\t\", on_bad_lines='warn')\n",
    "df=data[['Castaway','Job','Book','Luxury','Artist 1','Song 1','Artist 2','Song 2','Artist 3','Song 3']]\n",
    "# Before I set up the processing pipeline, let's do a quick check on the nulls in the dataset\n",
    "def print_nulls(column_name):\n",
    "    print(df[column_name].isnull().value_counts())\n",
    "\n",
    "[print_nulls(i) for i in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to clean the data and then vectorize the fields of interest. There's lots of nulls in the jobs column but this is only a nice-to-have anyway.\n",
    "We'll leave the nulls in but for data cleanliness we'll call them not-specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have so little data I want to retain as much as possible so I'll replace nans with 'not-specified'\n",
    "df= df.fillna('not-specified')\n",
    "#We can drop the classics since they are duplicates\n",
    "df= df.drop(df.loc[df['Castaway'].str.contains('Classic')].index, axis=0)\n",
    "#The first row has loaded the csv strangely so we can throw it out\n",
    "df.drop(0,axis=0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to start classifying the podcasts. To do this, I plan to:\n",
    "1. Vectorize the songs and average their values\n",
    "2. Vectorize their professions, books and luxury items\n",
    "3. Concatenate my two vectors\n",
    "4. Query my vector space using a podcast embedded with the same model\n",
    "\n",
    "NOTE: If this provides poor recommendations I'll have to add more context to the features - I could map synopsis of books, genres for songs and perhaps embed the wikipedia article of each castaway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize song values\n",
    "\n",
    "\n",
    "# Vectorize professions, books and luxury items"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
