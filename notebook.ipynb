{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Castaway\n",
      "False    3388\n",
      "Name: count, dtype: int64\n",
      "Job\n",
      "True     3234\n",
      "False     154\n",
      "Name: count, dtype: int64\n",
      "Book\n",
      "False    2942\n",
      "True      446\n",
      "Name: count, dtype: int64\n",
      "Luxury\n",
      "False    3180\n",
      "True      208\n",
      "Name: count, dtype: int64\n",
      "Artist 1\n",
      "False    3192\n",
      "True      196\n",
      "Name: count, dtype: int64\n",
      "Song 1\n",
      "False    3331\n",
      "True       57\n",
      "Name: count, dtype: int64\n",
      "Artist 2\n",
      "False    3185\n",
      "True      203\n",
      "Name: count, dtype: int64\n",
      "Song 2\n",
      "False    3331\n",
      "True       57\n",
      "Name: count, dtype: int64\n",
      "Artist 3\n",
      "False    3195\n",
      "True      193\n",
      "Name: count, dtype: int64\n",
      "Song 3\n",
      "False    3331\n",
      "True       57\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 35: expected 26 fields, saw 28\n",
      "Skipping line 42: expected 26 fields, saw 28\n",
      "Skipping line 45: expected 26 fields, saw 42\n",
      "Skipping line 59: expected 26 fields, saw 42\n",
      "Skipping line 2235: expected 26 fields, saw 40\n",
      "Skipping line 3131: expected 26 fields, saw 28\n",
      "Skipping line 3161: expected 26 fields, saw 28\n",
      "Skipping line 3166: expected 26 fields, saw 30\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"desert-island-discs-episodes.csv\", sep=\"\\t\", on_bad_lines='warn')\n",
    "df=data[['Castaway','Job','Book','Luxury','Artist 1','Song 1','Artist 2','Song 2','Artist 3','Song 3']]\n",
    "# Before I set up the processing pipeline, let's do a quick check on the nulls in the dataset\n",
    "def print_nulls(column_name):\n",
    "    print(df[column_name].isnull().value_counts())\n",
    "\n",
    "[print_nulls(i) for i in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to clean the data and then vectorize the fields of interest. There's lots of nulls in the jobs column but this is only a nice-to-have anyway.\n",
    "We'll leave the nulls in but for data cleanliness we'll call them not-specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_s/k6zmybnj6j1cgzb3bwm8bkym0000gn/T/ipykernel_65772/3068522413.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Job']= df['Job'].fillna('not-specified')\n"
     ]
    }
   ],
   "source": [
    "# We have so little data I want to retain as much as possible so I'll replace nans in job with 'not-specified'\n",
    "df['Job']= df['Job'].fillna('not-specified')\n",
    "#We can drop the classics since they are duplicates\n",
    "df= df.drop(df.loc[df['Castaway'].str.contains('Classic')].index, axis=0)\n",
    "#The first row has loaded the csv strangely so we can throw it out\n",
    "df.drop(0,axis=0,inplace=True)\n",
    "# Drop nans now\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to start classifying the podcasts. To do this, I plan to:\n",
    "1. Vectorize the songs and artists\n",
    "2. Vectorize their professions, books and luxury items\n",
    "3. Concatenate my two vectors\n",
    "4. Query my vector space using a podcast embedded with the same model\n",
    "\n",
    "NOTE: If this provides poor recommendations I'll have to add more context to the features - I could map synopsis of books, genres for songs and perhaps embed the wikipedia article of each castaway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for vectorizing\n",
    "\n",
    "# Group columns\n",
    "df['musicChoice']= df['Artist 1'] + ' ' + df['Song 1'] + ' ' + df['Artist 2'] + ' ' + df['Song 2'] + ' '+ df['Artist 3'] + ' ' + df['Song 3']\n",
    "df['extraChoices']= df['Job'] + ' ' + df['Book'] + ' ' + df['Luxury']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "tf = TfidfVectorizer(analyzer = 'word', ngram_range = (1, 3), min_df = 0, stop_words = \"english\")\n",
    "\n",
    "# Create vector embeddings for each choice\n",
    "tf_idf1 = tf.fit_transform(df['extraChoices'])\n",
    "tf_idf2 = tf.fit_transform(df['musicChoice'])\n",
    "combi_tf_idf= tf.fit_transform(df['musicChoice']+df['extraChoices'])\n",
    "cosine_sim= linear_kernel(combi_tf_idf,combi_tf_idf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the first pass at some vectors let's take a look at recommended podcasts based on similarity scores. I want to see the top three podcasts based on music choice, extras choices and then I'll combine the vectors and see the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for getting recommendations\n",
    "indices = pd.Series(df.index, index=df['Castaway']).drop_duplicates() \n",
    "\n",
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    # Get the index of the Castaway chosen\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Get the pairwsie similarity scores of all Castaways with that Castaway\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the podcasts based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 3 most similar Castaways - ignoring the 1st which will be the Castaway in question\n",
    "    sim_scores = sim_scores[1:4]\n",
    "\n",
    "    # Get the indices\n",
    "    pod_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar podcasts\n",
    "    return df.iloc[pod_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to try it out..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Castaway</th>\n",
       "      <th>Job</th>\n",
       "      <th>Book</th>\n",
       "      <th>Luxury</th>\n",
       "      <th>Artist 1</th>\n",
       "      <th>Song 1</th>\n",
       "      <th>Artist 2</th>\n",
       "      <th>Song 2</th>\n",
       "      <th>Artist 3</th>\n",
       "      <th>Song 3</th>\n",
       "      <th>musicChoice</th>\n",
       "      <th>extraChoices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>Delia Smith</td>\n",
       "      <td>not-specified</td>\n",
       "      <td>Autobiography by Saint Therese of Lisieux</td>\n",
       "      <td>Writing materials</td>\n",
       "      <td>Simon &amp; Garfunkel</td>\n",
       "      <td>The Sound Of Silence</td>\n",
       "      <td>Benjamin Britten</td>\n",
       "      <td>Missa brevis in D major</td>\n",
       "      <td>Tomaso Albinoni &amp; Remo Giazotto</td>\n",
       "      <td>Adagio in G Minor for Organ &amp; Strings</td>\n",
       "      <td>Simon &amp; Garfunkel The Sound Of Silence Benjami...</td>\n",
       "      <td>not-specified Autobiography by Saint Therese o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>Malcolm Muggeridge</td>\n",
       "      <td>not-specified</td>\n",
       "      <td>Writings by Dr Samuel Johnson</td>\n",
       "      <td>Beehive</td>\n",
       "      <td>Wolfgang Amadeus Mozart</td>\n",
       "      <td>Exsultate, jubilate</td>\n",
       "      <td>Tomaso Albinoni &amp; Remo Giazotto</td>\n",
       "      <td>Adagio in G Minor for Organ &amp; Strings</td>\n",
       "      <td>Antonín Dvořák</td>\n",
       "      <td>Cello Concerto in B Minor</td>\n",
       "      <td>Wolfgang Amadeus Mozart Exsultate, jubilate To...</td>\n",
       "      <td>not-specified Writings by Dr Samuel Johnson Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>Anna Raeburn</td>\n",
       "      <td>not-specified</td>\n",
       "      <td>Daughter of the Earth by Agnes Smedley</td>\n",
       "      <td>Indian tea</td>\n",
       "      <td>Tomaso Albinoni &amp; Remo Giazotto</td>\n",
       "      <td>Adagio in G Minor for Organ &amp; Strings</td>\n",
       "      <td>Paul Robeson</td>\n",
       "      <td>Ballad for Americans</td>\n",
       "      <td>Erik Satie</td>\n",
       "      <td>Trois Gymnopédies No.1</td>\n",
       "      <td>Tomaso Albinoni &amp; Remo Giazotto Adagio in G Mi...</td>\n",
       "      <td>not-specified Daughter of the Earth by Agnes S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Castaway            Job  \\\n",
       "1568         Delia Smith  not-specified   \n",
       "1595  Malcolm Muggeridge  not-specified   \n",
       "1740        Anna Raeburn  not-specified   \n",
       "\n",
       "                                           Book             Luxury  \\\n",
       "1568  Autobiography by Saint Therese of Lisieux  Writing materials   \n",
       "1595              Writings by Dr Samuel Johnson            Beehive   \n",
       "1740     Daughter of the Earth by Agnes Smedley         Indian tea   \n",
       "\n",
       "                             Artist 1                                 Song 1  \\\n",
       "1568                Simon & Garfunkel                   The Sound Of Silence   \n",
       "1595          Wolfgang Amadeus Mozart                    Exsultate, jubilate   \n",
       "1740  Tomaso Albinoni & Remo Giazotto  Adagio in G Minor for Organ & Strings   \n",
       "\n",
       "                             Artist 2                                 Song 2  \\\n",
       "1568                 Benjamin Britten                Missa brevis in D major   \n",
       "1595  Tomaso Albinoni & Remo Giazotto  Adagio in G Minor for Organ & Strings   \n",
       "1740                     Paul Robeson                   Ballad for Americans   \n",
       "\n",
       "                             Artist 3                                 Song 3  \\\n",
       "1568  Tomaso Albinoni & Remo Giazotto  Adagio in G Minor for Organ & Strings   \n",
       "1595                   Antonín Dvořák              Cello Concerto in B Minor   \n",
       "1740                       Erik Satie                 Trois Gymnopédies No.1   \n",
       "\n",
       "                                            musicChoice  \\\n",
       "1568  Simon & Garfunkel The Sound Of Silence Benjami...   \n",
       "1595  Wolfgang Amadeus Mozart Exsultate, jubilate To...   \n",
       "1740  Tomaso Albinoni & Remo Giazotto Adagio in G Mi...   \n",
       "\n",
       "                                           extraChoices  \n",
       "1568  not-specified Autobiography by Saint Therese o...  \n",
       "1595  not-specified Writings by Dr Samuel Johnson Be...  \n",
       "1740  not-specified Daughter of the Earth by Agnes S...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('Helen Mirren')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These look pretty close - at least Levi Roots does. Let's compare with Michael."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Castaway</th>\n",
       "      <th>Job</th>\n",
       "      <th>Book</th>\n",
       "      <th>Luxury</th>\n",
       "      <th>Artist 1</th>\n",
       "      <th>Song 1</th>\n",
       "      <th>Artist 2</th>\n",
       "      <th>Song 2</th>\n",
       "      <th>Artist 3</th>\n",
       "      <th>Song 3</th>\n",
       "      <th>musicChoice</th>\n",
       "      <th>extraChoices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>Helen Mirren</td>\n",
       "      <td>not-specified</td>\n",
       "      <td>The Bhagavad-Gita</td>\n",
       "      <td>Silk underwear</td>\n",
       "      <td>Max Bruch</td>\n",
       "      <td>Violin Concerto No. 1 in G Minor</td>\n",
       "      <td>Musical Youth</td>\n",
       "      <td>Pass The Dutchie</td>\n",
       "      <td>Tomaso Albinoni &amp; Remo Giazotto</td>\n",
       "      <td>Adagio in G Minor for Organ &amp; Strings</td>\n",
       "      <td>Max Bruch Violin Concerto No. 1 in G Minor Mus...</td>\n",
       "      <td>not-specified The Bhagavad-Gita Silk underwear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Castaway            Job               Book          Luxury  \\\n",
       "1546  Helen Mirren  not-specified  The Bhagavad-Gita  Silk underwear   \n",
       "\n",
       "       Artist 1                            Song 1       Artist 2  \\\n",
       "1546  Max Bruch  Violin Concerto No. 1 in G Minor  Musical Youth   \n",
       "\n",
       "                Song 2                         Artist 3  \\\n",
       "1546  Pass The Dutchie  Tomaso Albinoni & Remo Giazotto   \n",
       "\n",
       "                                     Song 3  \\\n",
       "1546  Adagio in G Minor for Organ & Strings   \n",
       "\n",
       "                                            musicChoice  \\\n",
       "1546  Max Bruch Violin Concerto No. 1 in G Minor Mus...   \n",
       "\n",
       "                                        extraChoices  \n",
       "1546  not-specified The Bhagavad-Gita Silk underwear  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Castaway']=='Helen Mirren']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recommendations are good but not great. The suggestions appear strong based on the Castaway's choices but maybe I need more information about the interviewee for the model to really work well... I'll try and source a new dataset with more information. I know BBC include a summary of the Castaway on each podcast page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V2 Using scraped synopsis data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>synopsis</th>\n",
       "      <th>castaway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>Robert Macfarlane is a writer whose books abou...</td>\n",
       "      <td>Robert Macfarlane, writer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              synopsis  \\\n",
       "601  Robert Macfarlane is a writer whose books abou...   \n",
       "\n",
       "                      castaway  \n",
       "601  Robert Macfarlane, writer  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Initialize vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "tf = TfidfVectorizer(analyzer = 'word', ngram_range = (1, 3), min_df = 0, stop_words = \"english\")\n",
    "\n",
    "df= pd.read_csv('synopsis_data.csv')\n",
    "df=df[['synopsis','castaway']][:1587]\n",
    "df['synopsis']=[df['synopsis'][x].replace(\"\\n\",\" \").replace(\"Show less\",\"\").replace(\"[Taken from the original programme material for this archive edition of Desert Island Discs]\",\"\").strip().replace(\"   \",\" \").replace(\"  \",\"\") for x in range(len(df['synopsis']))]\n",
    "df.loc[df[\"castaway\"].str.contains(\"Macfarlane\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer = 'word', ngram_range = (1, 3), min_df = 0, stop_words = \"english\")\n",
    "tf_idf3 = tf.fit_transform(df['synopsis'])\n",
    "cosine_sim= linear_kernel(tf_idf3,tf_idf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define function for getting recommendations\n",
    "indices = pd.Series(df.index, index=df['castaway'])\n",
    "indices[df['castaway'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "677    Claudia Rankine, poet\n",
       "Name: castaway, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['castaway'].loc[df['synopsis'].str.contains(\"Rankine\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_recommendations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_s/k6zmybnj6j1cgzb3bwm8bkym0000gn/T/ipykernel_88496/2585120186.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Robert Macfarlane, writer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_recommendations' is not defined"
     ]
    }
   ],
   "source": [
    "get_recommendations('Robert Macfarlane, writer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for getting recommendations\n",
    "indices = pd.Series(df.index, index=df['castaway'])\n",
    "\n",
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    # Get the index of the Castaway chosen\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Get the pairwsie similarity scores of all Castaways with that Castaway\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the podcasts based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 3 most similar Castaways - ignoring the 1st which will be the Castaway in question\n",
    "    sim_scores = sim_scores[0:4]\n",
    "\n",
    "    # Get the indices\n",
    "    pod_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar podcasts\n",
    "    out= df.iloc[pod_indices]\n",
    "    out['scores']=sim_scores\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V3 new word embeddings ##\n",
    "Clearly the new recommender isn't picking up much information from the castaway synopses. A TF-IDF vector embedding would match castaways who have similar words while ignoring context so I think this is probably why the recommendations are so poor. Let's try a word2vec embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/douglasbudge/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from matplotlib import pyplot\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "def _removeNonAscii(s):\n",
    "    return \"\".join(i for i in s if  ord(i)<128)\n",
    "\n",
    "def make_lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    text = text.split()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "def remove_html(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text = tokenizer.tokenize(text)\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "df['cleaned'] = df['synopsis'].apply(_removeNonAscii)\n",
    "\n",
    "df['cleaned'] = df.cleaned.apply(func = make_lower_case)\n",
    "df['cleaned'] = df.cleaned.apply(func = remove_stop_words)\n",
    "df['cleaned'] = df.cleaned.apply(func=remove_punctuation)\n",
    "df['cleaned'] = df.cleaned.apply(func=remove_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the description into words\n",
    "corpus = []\n",
    "for words in df['cleaned']:\n",
    "    corpus.append(words.split())\n",
    "\n",
    "# Load in Google model\n",
    "EMBEDDING_FILE = 'GoogleNews-vectors-negative300.bin.gz'\n",
    "google_word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "\n",
    "# Training our corpus with Google Pretrained Model\n",
    "\n",
    "google_model = Word2Vec(vector_size = 300, window=5, min_count = 2, workers = -1)\n",
    "google_model.build_vocab(corpus)\n",
    "\n",
    "#model.intersect_word2vec_format('./word2vec/GoogleNews-vectors-negative300.bin', lockf=1.0, binary=True)\n",
    "#google_model.intersect_word2vec_format(EMBEDDING_FILE, lockf=1.0, binary=True)\n",
    "\n",
    "google_model.train(corpus, total_examples=google_model.corpus_count, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the average word2vec for the each book description\n",
    "def vectors(x):\n",
    "    \n",
    "    # Creating a list for storing the vectors (description into vectors)\n",
    "    global word_embeddings\n",
    "    word_embeddings = []\n",
    "\n",
    "    # Reading the each book description \n",
    "    for line in df['cleaned']:\n",
    "        avgword2vec = None\n",
    "        count = 0\n",
    "        for word in line.split():\n",
    "            if word in google_model.wv.index_to_key:\n",
    "                count += 1\n",
    "                if avgword2vec is None:\n",
    "                    avgword2vec = google_model.wv[word]\n",
    "                else:\n",
    "                    avgword2vec = avgword2vec + google_model.wv[word]\n",
    "                \n",
    "        if avgword2vec is not None:\n",
    "            avgword2vec = avgword2vec / count\n",
    "        \n",
    "            word_embeddings.append(avgword2vec)\n",
    "\n",
    "\n",
    "# Recommending the Top 5 similar books\n",
    "\n",
    "def recommendations(title):\n",
    "    \n",
    "    # Calling the function vectors\n",
    "\n",
    "    vectors(df)\n",
    "    \n",
    "    # finding cosine similarity for the vectors\n",
    "\n",
    "    cosine_similarities = cosine_similarity(word_embeddings, word_embeddings)\n",
    "\n",
    "    # taking the title and book image link and store in new data frame called books\n",
    "    pods = df[['castaway', 'synopsis']]\n",
    "    #Reverse mapping of the index\n",
    "    indices = pd.Series(df.index, index = df['castaway']).drop_duplicates()\n",
    "         \n",
    "    idx = indices[title]\n",
    "    sim_scores = list(enumerate(cosine_similarities[idx]))\n",
    "    sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)\n",
    "    sim_scores = sim_scores[1:6]\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "    recommend = pods.iloc[book_indices]\n",
    "    return recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                        castaway  \\\n",
       " 563  Bernardine Evaristo, writer   \n",
       " 614          Neil Gaiman, writer   \n",
       " 611        Joanne Harris, writer   \n",
       " 547             Brian Cox, actor   \n",
       " 612   Dame Jo da Silva, engineer   \n",
       " \n",
       "                                               synopsis  \n",
       " 563  Bernardine Evaristo won the Booker Prize in 20...  \n",
       " 614  Neil Gaiman is a writer whose list of titles s...  \n",
       " 611  Joanne Harris is a writer who is best known fo...  \n",
       " 547  Brian Cox CBE is a Scottish actor whose career...  \n",
       " 612  Dame Jo da Silva is a structural engineer and ...  ,\n",
       " [(563, 0.4351024),\n",
       "  (614, 0.40417996),\n",
       "  (611, 0.4036488),\n",
       "  (547, 0.38638803),\n",
       "  (612, 0.3823595)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations('Claudia Rankine, poet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
