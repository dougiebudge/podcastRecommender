{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    3388\n",
      "Name: Castaway, dtype: int64\n",
      "True     3234\n",
      "False     154\n",
      "Name: Job, dtype: int64\n",
      "False    2942\n",
      "True      446\n",
      "Name: Book, dtype: int64\n",
      "False    3181\n",
      "True      207\n",
      "Name: Luxury, dtype: int64\n",
      "False    3193\n",
      "True      195\n",
      "Name: Artist 1, dtype: int64\n",
      "False    3331\n",
      "True       57\n",
      "Name: Song 1, dtype: int64\n",
      "False    3185\n",
      "True      203\n",
      "Name: Artist 2, dtype: int64\n",
      "False    3331\n",
      "True       57\n",
      "Name: Song 2, dtype: int64\n",
      "False    3195\n",
      "True      193\n",
      "Name: Artist 3, dtype: int64\n",
      "False    3331\n",
      "True       57\n",
      "Name: Song 3, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 35: expected 26 fields, saw 28\\nSkipping line 42: expected 26 fields, saw 28\\nSkipping line 45: expected 26 fields, saw 42\\nSkipping line 59: expected 26 fields, saw 42\\nSkipping line 2235: expected 26 fields, saw 40\\nSkipping line 3131: expected 26 fields, saw 28\\nSkipping line 3161: expected 26 fields, saw 28\\nSkipping line 3166: expected 26 fields, saw 30\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"desert-island-discs-episodes.csv\", sep=\"\\t\", on_bad_lines='warn')\n",
    "df=data[['Castaway','Job','Book','Luxury','Artist 1','Song 1','Artist 2','Song 2','Artist 3','Song 3']]\n",
    "# Before I set up the processing pipeline, let's do a quick check on the nulls in the dataset\n",
    "def print_nulls(column_name):\n",
    "    print(df[column_name].isnull().value_counts())\n",
    "\n",
    "[print_nulls(i) for i in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to clean the data and then vectorize the fields of interest. There's lots of nulls in the jobs column but this is only a nice-to-have anyway.\n",
    "We'll leave the nulls in but for data cleanliness we'll call them not-specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_s/k6zmybnj6j1cgzb3bwm8bkym0000gn/T/ipykernel_9726/3068522413.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Job']= df['Job'].fillna('not-specified')\n"
     ]
    }
   ],
   "source": [
    "# We have so little data I want to retain as much as possible so I'll replace nans in job with 'not-specified'\n",
    "df['Job']= df['Job'].fillna('not-specified')\n",
    "#We can drop the classics since they are duplicates\n",
    "df= df.drop(df.loc[df['Castaway'].str.contains('Classic')].index, axis=0)\n",
    "#The first row has loaded the csv strangely so we can throw it out\n",
    "df.drop(0,axis=0,inplace=True)\n",
    "# Drop nans now\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to start classifying the podcasts. To do this, I plan to:\n",
    "1. Vectorize the songs and artists\n",
    "2. Vectorize their professions, books and luxury items\n",
    "3. Concatenate my two vectors\n",
    "4. Query my vector space using a podcast embedded with the same model\n",
    "\n",
    "NOTE: If this provides poor recommendations I'll have to add more context to the features - I could map synopsis of books, genres for songs and perhaps embed the wikipedia article of each castaway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for vectorizing\n",
    "\n",
    "# Group columns\n",
    "df['musicChoice']= df['Artist 1'] + ' ' + df['Song 1'] + ' ' + df['Artist 2'] + ' ' + df['Song 2'] + ' '+ df['Artist 3'] + ' ' + df['Song 3']\n",
    "df['extraChoices']= df['Job'] + ' ' + df['Book'] + ' ' + df['Luxury']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "tf = TfidfVectorizer(analyzer = 'word', ngram_range = (1, 3), min_df = 0, stop_words = \"english\")\n",
    "\n",
    "# Create vector embeddings for each choice\n",
    "tf_idf1 = tf.fit_transform(df['extraChoices'])\n",
    "tf_idf2 = tf.fit_transform(df['musicChoice'])\n",
    "\n",
    "cosine_sim= linear_kernel(tf_idf2,tf_idf2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the first pass at some vectors let's take a look at recommended podcasts based on similarity scores. I want to see the top three podcasts based on music choice, extras choices and then I'll combine the vectors and see the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for getting recommendations\n",
    "indices = pd.Series(df.index, index=df['Castaway']).drop_duplicates() \n",
    "\n",
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    # Get the index of the Castaway chosen\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Get the pairwsie similarity scores of all Castaways with that Castaway\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the podcasts based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 3 most similar Castaways - ignoring the 1st which will be the Castaway in question\n",
    "    sim_scores = sim_scores[1:4]\n",
    "\n",
    "    # Get the indices\n",
    "    pod_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar podcasts\n",
    "    return df[['Castaway', 'musicChoice', 'extraChoices']].iloc[pod_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to try it out..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Castaway</th>\n",
       "      <th>musicChoice</th>\n",
       "      <th>extraChoices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Dame Katherine Grainger</td>\n",
       "      <td>Tina Turner Proud Mary Miriam Makeba Pata Pata...</td>\n",
       "      <td>not-specified Book of Quotations Archive of pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Amanda Khozi Mukwashi</td>\n",
       "      <td>Miriam Makeba Pata Pata Jacques Arcadelt Ave M...</td>\n",
       "      <td>charity CEO Who Moved My Cheese? by Dr Spencer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Levi Roots</td>\n",
       "      <td>Stevie Wonder Master Blaster (Jammin') Bob Mar...</td>\n",
       "      <td>not-specified Long Walk To Freedom by Nelson M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Castaway  \\\n",
       "220  Dame Katherine Grainger   \n",
       "53     Amanda Khozi Mukwashi   \n",
       "245               Levi Roots   \n",
       "\n",
       "                                           musicChoice  \\\n",
       "220  Tina Turner Proud Mary Miriam Makeba Pata Pata...   \n",
       "53   Miriam Makeba Pata Pata Jacques Arcadelt Ave M...   \n",
       "245  Stevie Wonder Master Blaster (Jammin') Bob Mar...   \n",
       "\n",
       "                                          extraChoices  \n",
       "220  not-specified Book of Quotations Archive of pa...  \n",
       "53   charity CEO Who Moved My Cheese? by Dr Spencer...  \n",
       "245  not-specified Long Walk To Freedom by Nelson M...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('Michael Holding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recommendations are good but not great. The suggestions appear strong based on the Castaway's choices but maybe I need more information about the interviewee for the model to really work well... I'll try and source a new dataset with more information. I know BBC include a summary of the Castaway on each podcast page."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
